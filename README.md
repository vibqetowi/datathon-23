# About
This repository is Team 23's submission for the Polyfinance Datathon. Our team consists of three members, two of whom have some experience in trading, but not with quantitative strategies, and none of us have previous experience in machine learning.

## Project Overview
The goal of this project was to create a trading algorithm that operates within a specified historical period (2000-2015) with the aim of optimizing ROI. The strategy had to include at least 120 stocks from a pre-selected pool of 304 S&P 500 stocks, rebalance daily, and avoid using future information.

We aimed to leverage the correlation between industry performance and the daily movements of the S&P 500 index. The algorithm was designed to favor industries with a higher correlation on green days and a lower correlation on red days.

### Structure of the Project:
- The "work_files" folder contains our working code files.
- The "online_tutorials" folder includes resources we used while learning the basics through tutorials.
- The "model_save" folder contains our exported models. We apologize for any inconvenience this may cause, as it was more manageable than exporting model weights.
- The "kaggle" folder contains additional public data, either generated by splitting the current dataset or sourced from public platforms like Yahoo Finance.

### Assumptions
- The starting value of the portfolio is $1 million, as provided by the Polyfinance team.
- The objective is to outperform the S&P 500 over the period from 2000 to 2015.

## Methodology
After discussions, we split into two teams: the prediction team and the strategy team. This division was intended to parallelize the work. The first team focused on trading based on future returns, and later, we replaced actual future returns with predictions. If the prediction algorithm proves accurate, this should yield similar results.

### Industry Correlation Analysis
The "industry_correlations.ipynb" script calculates the daily percentage return for each industry and the S&P 500, separates the returns into green and red days based on the S&P 500's performance, and calculates correlation coefficients for each scenario.

The script's functionality includes:
1. Data Import: Importing and timestamping industry data for accurate analysis.
2. Return Calculation: Computing daily returns for both the industry and the S&P 500.
3. Day Classification: Classifying days as green or red based on S&P 500 performance.
4. Correlation Calculation: Calculating and storing correlation coefficients for green and red days.
5. Industry Selection: Selecting industries based on a linear regression model that fits green-day correlation against red-day correlation, prioritizing those with the highest green-day correlation and lowest red-day correlation.

### Stock Prediction Model
Our work is documented in "stock_prediction.ipynb."

Our rationale was that predicting the percentage return is more important than the closing price. If we can accurately predict percentage moves, we can identify and trade overperformers and underperformers in any period.

The chosen model was LSTM, primarily because initial research suggested RNNs are effective for time series data, and a YouTube tutorial was easy to follow. The decision regarding the architecture was arbitrary; we planned to iterate the number of layers for optimal performance but lacked the time.

Feature selection was approached broadly; we included every indicator from workshops and various blogs, then attempted algorithmic feature engineering. Manual engineering proved challenging; we found little correlation between current values and the next day's return. Even after days of effort, the mean squared error never fell below 0.0025. While this seems promising in theory, in practice, our first stock predictions had errors up to 40%, only marginally better than a coin flip.

We observed that the LSTM, while effective at predicting actual prices with a slight delay, was not as successful at predicting returns, at least in our implementation. The model tended to predict very steady percentage variations close to 0%, contrasting with the real data's volatility. We considered adjusting the model to make less conservative predictions or questioning the daily resolution's effectiveness, but it's unclear how switching to a monthly or higher resolution would improve the results.

We also experimented with polynomial and random forest models, but time and resource constraints limited these explorations. However as shown by the benchmark, a simple model with random weights performed extremely well so perhaps the winning strategy would have been way simpler.

### Miscellaneous
the other notebooks contain our exploratory data analysis and other things. They could be interesting to some.

## What Was Envisioned But Not Implemented
### LSTM Model
We planned to incorporate an LSTM model to account for industry distinctions in making predictions. Each symbol was split by correlation with the S&P and we intended to train one model per correlation bucket.

### Cumulative Performance
We calculated the cumulative percentage performance of individual S&P stocks versus the S&P 500 index, intending to inform stock selection through a moving average crossover strategy.

### What Went Wrong
### RNN Integration Issues
We faced challenges integrating Recurrent Neural Networks (RNNs), mainly due to a knowledge gap that made their implementation unfeasible within the challenge's constraints and timeframe.

### Technical Hurdles
Optimizing for alpha, accounting for trading fees, and adhering to the challenge's

 fundamental constraints were difficult, hindering the project's technical potential.

## Learning Outcomes
Despite the setbacks, this project was a significant educational journey, offering insights into portfolio management and machine learning.